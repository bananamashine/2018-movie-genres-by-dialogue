{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import multiprocess, pickle, warnings, re, gc\n",
    "from operator import itemgetter\n",
    "from typing import List, Dict\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autotime\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.metrics import log_loss, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "def on_field(f: str, *vec) -> Pipeline:\n",
    "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/bananamachine/.kaggle/competitions/movie-genres-by-dialogue/train.csv.zip')\n",
    "test = pd.read_csv('/home/bananamachine/.kaggle/competitions/movie-genres-by-dialogue/X_test.csv.zip')\n",
    "\n",
    "def clean_labels(text):\n",
    "    text = re.sub('-', '', text)\n",
    "    return text \n",
    "\n",
    "train.genres = train.genres.map(lambda x: clean_labels(x))\n",
    "\n",
    "label_vectorizer = CountVectorizer()\n",
    "train_y = label_vectorizer.fit_transform(train.genres).todense()\n",
    "label_cols = label_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = make_union(\n",
    "    on_field('dialogue', TfidfVectorizer(sublinear_tf=True, token_pattern='\\w+')),\n",
    ")\n",
    "\n",
    "train_X = vectorizer.fit_transform(train)\n",
    "test_X = vectorizer.transform(test)\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    \n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('val_auc' in self.params['metrics']):\n",
    "            self.params['metrics'].append('roc_auc_val')        \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['val_auc'] = float('-inf')\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            logs['val_auc'] = score\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "def get_model(params):\n",
    "    inp = Input(shape=(train_X.shape[1],), dtype='float32', sparse=True)\n",
    "    out = Dense(params['d0'], activation='relu', )(inp)\n",
    "    out = Dropout(params['dr0'])(out)\n",
    "    out = Dense(params['d1'], activation='relu', )(out)\n",
    "    out = Dropout(params['dr1'])(out)                    \n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = Model(inp, out)     \n",
    "    return model\n",
    "\n",
    "def val_run_model(train_X, train_y, val_X, val_y, test_X, params): \n",
    "\n",
    "    try: pp = multiprocess.current_process()._identity[0]\n",
    "    except IndexError: pp = 0\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session(config=config) as sess:\n",
    "            K.set_session(sess)\n",
    "            \n",
    "            model = get_model(params)\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "            \n",
    "            file_path, log_file_path = 'mlpword_auc_checkpoint_{}.hdf5'.format(str(pp)), 'mlpword_csv_log_{}.csv'.format(str(pp))\n",
    "            rocauc = RocAucEvaluation(validation_data=(val_X, val_y), interval=1)\n",
    "            lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=3, min_lr=0.5e-6)\n",
    "            early_stopper = EarlyStopping(monitor='val_auc', mode='max', patience=6)\n",
    "            csv_logger = CSVLogger(log_file_path)\n",
    "            checkpoint = ModelCheckpoint(file_path, monitor='val_auc', verbose=0, save_best_only=True, mode='max')           \n",
    "            callbacks_list = [rocauc, lr_reducer, early_stopper, csv_logger, checkpoint]\n",
    "            \n",
    "            model.fit(train_X, train_y, batch_size=params['bs'], epochs=40, validation_data=(val_X, val_y), verbose=0, callbacks=callbacks_list)\n",
    "            model.load_weights(file_path)\n",
    "            pred_val_y = model.predict(val_X, batch_size=512)\n",
    "            pred_test_y = model.predict(test_X, batch_size=512)\n",
    "\n",
    "            sess.close()\n",
    "            del sess, model, lr_reducer, early_stopper, checkpoint, csv_logger; gc.collect();\n",
    "    return pred_val_y, pred_test_y                  \n",
    "  \n",
    "def val_predict_fold(i, dev_index, val_index, params): \n",
    "    pred_train = np.zeros(train_X.shape[0])\n",
    "    dev_X, val_X = train_X[dev_index], train_X[val_index]\n",
    "    dev_y, val_y = np.squeeze(np.array(train_y[:, i][dev_index])), np.squeeze(np.array(train_y[:, i][val_index]))\n",
    "    pred_val_y, pred_test_y = val_run_model(dev_X, dev_y, val_X, val_y, test_X, params)\n",
    "    pred_train[val_index] = np.squeeze(np.array(pred_val_y))\n",
    "    cv_scores = roc_auc_score(val_y, pred_val_y)\n",
    "    return cv_scores, pred_train, pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_predict_oof(i, n, params):  \n",
    "    if __name__ == '__main__':\n",
    "        kf = StratifiedKFold(n_splits=n, shuffle=True, random_state=0)\n",
    "        with multiprocess.Pool(n) as p:\n",
    "            r = list(p.imap(lambda x: val_predict_fold(i, x[0], x[1], params), kf.split(train_y[:, i], train_y[:, i]), chunksize=1))\n",
    "    return r, np.mean([x[0] for x in r]), np.sum([x[1] for x in r], axis=0), np.sum([x[2] for x in r], axis=0) / float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'd0': 512,\n",
    "    'dr0': .6,\n",
    "    'd1': 256,\n",
    "    'dr1': .5,\n",
    "    'bs': 512,\n",
    "}\n",
    "\n",
    "preds_test = np.zeros((test_X.shape[0], len(label_cols)))\n",
    "preds_train = np.zeros((train_X.shape[0], len(label_cols)))\n",
    "cv_scores = list()\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('cv', j)\n",
    "    r, scores, pred_train, pred_test = val_predict_oof(i, 5, params)\n",
    "    preds_train[:, i] = pred_train\n",
    "    preds_test[:, i] = pred_test.flatten()\n",
    "    cv_scores.append(np.mean(scores))\n",
    "    print(np.mean(scores))\n",
    "    \n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    train['pred_mlp0_{}'.format(str(i))] = preds_train[:, i]\n",
    "    test['pred_mlp0_{}'.format(str(i))] = preds_test[:, i]\n",
    "    \n",
    "train.iloc[:, -20:].to_csv('predictions/pred_train_mlp0.csv', index=False)\n",
    "test.iloc[:, -20:].to_csv('predictions/pred_test_mlp0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
